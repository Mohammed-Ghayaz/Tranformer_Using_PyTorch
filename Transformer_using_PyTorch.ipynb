{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPbgEqqfXUrsOIWOCLt/5QV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np"],"metadata":{"id":"vsI6fx1SBHLW","executionInfo":{"status":"ok","timestamp":1750930138473,"user_tz":-330,"elapsed":6426,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        divterm = torch.arange(0, d_model, 2).float() / d_model\n","        divterm = 1 / (10000 ** divterm)\n","        position = torch.arange(max_len).float().unsqueeze(1)\n","        pe[:, 0::2] = torch.sin(divterm * position)\n","        pe[:, 1::2] = torch.cos(divterm * position)\n","        self.pe = pe.unsqueeze(0)\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1)].to(x.device)"],"metadata":{"id":"WFFlbcIRDer3","executionInfo":{"status":"ok","timestamp":1750930140843,"user_tz":-330,"elapsed":5,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F\n","import math\n","\n","def attention_mechanism(Q, K, V, mask=None):\n","    d_k = Q.size(-1)\n","    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n","\n","    if mask is not None:\n","        scores = scores.masked_fill(mask == 0, float('-inf'))\n","\n","    attention_weights = F.softmax(scores, dim=-1)\n","    output = torch.matmul(attention_weights, V)\n","\n","    return output, attention_weights"],"metadata":{"id":"7E6b1iDDOYIU","executionInfo":{"status":"ok","timestamp":1750932581968,"user_tz":-330,"elapsed":42,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, d_model, num_heads=1):\n","    super(MultiHeadAttention, self).__init__()\n","    self.d_model = d_model\n","    self.num_heads = num_heads\n","    self.d_k = d_model\n","\n","    self.W_q = nn.Linear(d_model, d_model * num_heads)\n","    self.W_k = nn.Linear(d_model, d_model * num_heads)\n","    self.W_v = nn.Linear(d_model, d_model * num_heads)\n","    self.W_o = nn.Linear(d_model * num_heads, d_model)\n","\n","  def forward(self, x, mask=None):\n","    Q = self.W_q(x)\n","    K = self.W_k(x)\n","    V = self.W_v(x)\n","\n","    Q = Q.view(Q.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","    K = K.view(K.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","    V = V.view(V.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    output, attention_weights = attention_mechanism(Q, K, V, mask)\n","\n","    return self.W_o(output.transpose(1, 2).contiguous().view(output.size(0), output.size(2), -1))"],"metadata":{"id":"E_EiSmr_F16w","executionInfo":{"status":"ok","timestamp":1750932681181,"user_tz":-330,"elapsed":72,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  def __init__(self, d_model, num_heads, d_ff):\n","    super(Encoder, self).__init__()\n","    self.multihead_attention = MultiHeadAttention(d_model, num_heads)\n","    self.layer_norm1 = nn.LayerNorm(d_model)\n","    self.layer_norm2 = nn.LayerNorm(d_model)\n","    self.d_ff = nn.Sequential(\n","        nn.Linear(d_model, d_ff),\n","        nn.ReLU(),\n","        nn.Linear(d_ff, d_model)\n","    )\n","\n","  def forward(self, x):\n","    attention_output = self.multihead_attention(x)\n","    x = self.layer_norm1(x + attention_output)\n","    ff_output = self.d_ff(x)\n","    x = self.layer_norm2(x + ff_output)\n","\n","    return x"],"metadata":{"id":"NRI1fH9DJC4G","executionInfo":{"status":"ok","timestamp":1750934243207,"user_tz":-330,"elapsed":4,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["class EncoderOnlyTransformer(nn.Module):\n","  def __init__(self, vocab_size, d_model, num_heads, d_ff, num_layers):\n","    super(EncoderOnlyTransformer, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, d_model)\n","    self.positional_encoding = PositionalEncoding(d_model)\n","    self.encoder_layers = nn.ModuleList([\n","        Encoder(d_model, num_heads, d_ff) for _ in range(num_layers)\n","    ])\n","\n","  def forward(self, x):\n","    x = self.embedding(x)\n","    x = self.positional_encoding(x)\n","    for layer in self.encoder_layers:\n","      x = layer(x)\n","\n","    return x"],"metadata":{"id":"0DdENYYWo084","executionInfo":{"status":"ok","timestamp":1750934244194,"user_tz":-330,"elapsed":5,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class CrossAttention(nn.Module):\n","  def __init__(self, d_model, num_heads=1):\n","    super(CrossAttention, self).__init__()\n","    self.d_model = d_model\n","    self.num_heads = num_heads\n","    self.d_k = d_model\n","\n","    self.W_q = nn.Linear(d_model, d_model * num_heads)\n","    self.W_k = nn.Linear(d_model, d_model * num_heads)\n","    self.W_v = nn.Linear(d_model, d_model * num_heads)\n","    self.W_o = nn.Linear(d_model * num_heads, d_model)\n","\n","  def forward(self, src, tgt, mask=None):\n","    Q = self.W_q(tgt)\n","    K = self.W_k(src)\n","    V = self.W_v(src)\n","\n","    Q = Q.view(Q.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","    K = K.view(K.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","    V = V.view(V.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    output, attention_weights = attention_mechanism(Q, K, V, mask)\n","\n","    return self.W_o(output.transpose(1, 2).contiguous().view(output.size(0), output.size(2), -1))"],"metadata":{"id":"MxMw76vBpc3o","executionInfo":{"status":"ok","timestamp":1750934245207,"user_tz":-330,"elapsed":9,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","  def __init__(self, d_model, num_heads, d_ff):\n","    super(Decoder, self).__init__()\n","    self.cross_attention = CrossAttention(d_model, num_heads)\n","    self.layer_norm1 = nn.LayerNorm(d_model)\n","    self.layer_norm2 = nn.LayerNorm(d_model)\n","    self.layer_norm3 = nn.LayerNorm(d_model)\n","    self.d_ff = nn.Sequential([\n","        nn.Linear(d_model, d_ff),\n","        nn.ReLU(),\n","        nn.Linear(d_ff, d_model)\n","    ])\n","    self.masked_multihead_attention = MultiHeadAttention(d_model, num_heads)\n","\n","  def forward(self, x, encoder_output, mask):\n","    cross_attention_output = self.cross_attention(encoder_output, x, mask)\n","    x = self.layer_norm1(x + cross_attention_output)\n","    masked_multihead_attention_output = self.masked_multihead_attention(x, mask)\n","    x = self.layer_norm2(x + masked_multihead_attention_output)\n","    ff_output = self.d_ff(x)\n","    x = self.layer_norm3(x + ff_output)\n","\n","    return x"],"metadata":{"id":"u1dNS_EvsECA","executionInfo":{"status":"ok","timestamp":1750934245962,"user_tz":-330,"elapsed":6,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["class DecoderPart(nn.Module):\n","  def __init__(self, vocab_size, d_model, num_heads, num_layers, dff):\n","    super(DecoderPart, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, d_model)\n","    self.pos_encoding = PositionalEncoding(vocab_size, d_model)\n","    self.decoder_layers = nn.ModuleList([Decoder(d_model, num_heads, dff, vocab_size) for _ in range(num_layers)])\n","\n","  def forward(self, x, encoder_output, mask):\n","    x = self.embedding(x)\n","    x = self.pos_encoding(x)\n","    for layer in self.decoder_layers:\n","      x = layer(x, encoder_output, mask)\n","\n","    return x"],"metadata":{"id":"cVmUlhs6vbNV","executionInfo":{"status":"ok","timestamp":1750934246861,"user_tz":-330,"elapsed":5,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["class Transformer(nn.Module):\n","  def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, dff):\n","    super(Transformer, self).__init__()\n","    self.encoder = EncoderOnlyTransformer(src_vocab_size, d_model, num_heads, dff, num_layers)\n","    self.decoder = DecoderPart(tgt_vocab_size, d_model, num_heads, dff, num_layers)\n","    self.final_layer = nn.Linear(d_model, tgt_vocab_size)\n","\n","  def forward(self, src, tgt, mask):\n","    encoder_output = self.encoder(src)\n","    decoder_output = self.decoder(tgt, encoder_output, mask)\n","    output = self.final_layer(decoder_output)\n","\n","    return output"],"metadata":{"id":"hyC07HMsxrcn","executionInfo":{"status":"ok","timestamp":1750934247833,"user_tz":-330,"elapsed":13,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WPuHunfGzMsN"},"execution_count":null,"outputs":[]}]}