{"cells":[{"cell_type":"code","execution_count":84,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1750945557438,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"vsI6fx1SBHLW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np"]},{"cell_type":"code","execution_count":85,"metadata":{"executionInfo":{"elapsed":40,"status":"ok","timestamp":1750945557476,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"WFFlbcIRDer3"},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        divterm = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n","        position = torch.arange(max_len).float().unsqueeze(1)\n","        pe[:, 0::2] = torch.sin(divterm.unsqueeze(0) * position)\n","        pe[:, 1::2] = torch.cos(divterm.unsqueeze(0) * position)\n","        self.pe = pe.unsqueeze(0)\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1)].to(x.device)"]},{"cell_type":"code","execution_count":86,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1750945557487,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"7E6b1iDDOYIU"},"outputs":[],"source":["import torch.nn.functional as F\n","import math\n","\n","def attention_mechanism(Q, K, V, mask=None):\n","    d_k = Q.size(-1)\n","    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)\n","\n","    if mask is not None:\n","        scores = scores.masked_fill(mask == 0, float('-inf'))\n","\n","    attention_weights = F.softmax(scores, dim=-1)\n","    output = torch.matmul(attention_weights, V)\n","\n","    return output, attention_weights"]},{"cell_type":"code","execution_count":87,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1750945557516,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"E_EiSmr_F16w"},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, d_model, num_heads=1):\n","    super(MultiHeadAttention, self).__init__()\n","    self.d_model = d_model\n","    self.num_heads = num_heads\n","    self.d_k = d_model\n","\n","    self.W_q = nn.Linear(d_model, d_model * num_heads)\n","    self.W_k = nn.Linear(d_model, d_model * num_heads)\n","    self.W_v = nn.Linear(d_model, d_model * num_heads)\n","    self.W_o = nn.Linear(d_model * num_heads, d_model)\n","\n","  def forward(self, x, mask=None):\n","    Q = self.W_q(x)\n","    K = self.W_k(x)\n","    V = self.W_v(x)\n","\n","    Q = Q.view(Q.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","    K = K.view(K.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","    V = V.view(V.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    output, attention_weights = attention_mechanism(Q, K, V, mask)\n","\n","    return self.W_o(output.transpose(1, 2).contiguous().view(output.size(0), output.size(2), -1))"]},{"cell_type":"code","execution_count":88,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1750945557518,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"NRI1fH9DJC4G"},"outputs":[],"source":["class Encoder(nn.Module):\n","  def __init__(self, d_model, num_heads, d_ff):\n","    super(Encoder, self).__init__()\n","    self.multihead_attention = MultiHeadAttention(d_model, num_heads)\n","    self.layer_norm1 = nn.LayerNorm(d_model)\n","    self.layer_norm2 = nn.LayerNorm(d_model)\n","    self.d_ff = nn.Sequential(\n","        nn.Linear(d_model, d_ff),\n","        nn.ReLU(),\n","        nn.Linear(d_ff, d_model)\n","    )\n","\n","  def forward(self, x):\n","    attention_output = self.multihead_attention(x)\n","    x = self.layer_norm1(x + attention_output)\n","    ff_output = self.d_ff(x)\n","    x = self.layer_norm2(x + ff_output)\n","\n","    return x"]},{"cell_type":"code","execution_count":89,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1750945557535,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"0DdENYYWo084"},"outputs":[],"source":["class EncoderOnlyTransformer(nn.Module):\n","  def __init__(self, vocab_size, d_model, num_heads, d_ff, num_layers):\n","    super(EncoderOnlyTransformer, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, d_model)\n","    self.positional_encoding = PositionalEncoding(d_model)\n","    self.encoder_layers = nn.ModuleList([\n","        Encoder(d_model, num_heads, d_ff) for _ in range(num_layers)\n","    ])\n","\n","  def forward(self, x):\n","    x = self.embedding(x)\n","    x = self.positional_encoding(x)\n","    for layer in self.encoder_layers:\n","      x = layer(x)\n","\n","    return x"]},{"cell_type":"code","execution_count":90,"metadata":{"executionInfo":{"elapsed":173,"status":"ok","timestamp":1750945557710,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"MxMw76vBpc3o"},"outputs":[],"source":["class CrossAttention(nn.Module):\n","  def __init__(self, d_model, num_heads=1):\n","    super(CrossAttention, self).__init__()\n","    self.d_model = d_model\n","    self.num_heads = num_heads\n","    self.d_k = d_model\n","\n","    self.W_q = nn.Linear(d_model, d_model * num_heads)\n","    self.W_k = nn.Linear(d_model, d_model * num_heads)\n","    self.W_v = nn.Linear(d_model, d_model * num_heads)\n","    self.W_o = nn.Linear(d_model * num_heads, d_model)\n","\n","  def forward(self, src, tgt, mask=None):\n","    Q = self.W_q(tgt)\n","    K = self.W_k(src)\n","    V = self.W_v(src)\n","\n","    Q = Q.view(Q.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","    K = K.view(K.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","    V = V.view(V.size(0), -1, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    output, attention_weights = attention_mechanism(Q, K, V, mask)\n","\n","    return self.W_o(output.transpose(1, 2).contiguous().view(output.size(0), output.size(2), -1))"]},{"cell_type":"code","execution_count":91,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1750945557714,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"u1dNS_EvsECA"},"outputs":[],"source":["class Decoder(nn.Module):\n","  def __init__(self, d_model, num_heads, d_ff):\n","    super(Decoder, self).__init__()\n","    self.cross_attention = CrossAttention(d_model, num_heads)\n","    self.layer_norm1 = nn.LayerNorm(d_model)\n","    self.layer_norm2 = nn.LayerNorm(d_model)\n","    self.layer_norm3 = nn.LayerNorm(d_model)\n","    self.d_ff = nn.Sequential(\n","        nn.Linear(d_model, d_ff),\n","        nn.ReLU(),\n","        nn.Linear(d_ff, d_model)\n","    )\n","    self.masked_multihead_attention = MultiHeadAttention(d_model, num_heads)\n","\n","  def forward(self, x, encoder_output, mask):\n","    masked_multihead_attention_output = self.masked_multihead_attention(x, mask)\n","    x = self.layer_norm1(x + masked_multihead_attention_output)\n","    cross_attention_output = self.cross_attention(encoder_output, x)\n","    x = self.layer_norm2(x + cross_attention_output)\n","    ff_output = self.d_ff(x)\n","    x = self.layer_norm3(x + ff_output)\n","\n","    return x"]},{"cell_type":"code","execution_count":92,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1750945557721,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"cVmUlhs6vbNV"},"outputs":[],"source":["class DecoderPart(nn.Module):\n","  def __init__(self, vocab_size, d_model, num_heads, num_layers, dff):\n","    super(DecoderPart, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, d_model)\n","    self.pos_encoding = PositionalEncoding(d_model)\n","    self.decoder_layers = nn.ModuleList([Decoder(d_model, num_heads, dff) for _ in range(num_layers)])\n","\n","  def forward(self, x, encoder_output, mask):\n","    x = self.embedding(x)\n","    x = self.pos_encoding(x)\n","    for layer in self.decoder_layers:\n","      x = layer(x, encoder_output, mask)\n","\n","    return x"]},{"cell_type":"code","execution_count":93,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1750945557723,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"hyC07HMsxrcn"},"outputs":[],"source":["class Transformer(nn.Module):\n","  def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, dff):\n","    super(Transformer, self).__init__()\n","    self.encoder = EncoderOnlyTransformer(src_vocab_size, d_model, num_heads, dff, num_layers)\n","    self.decoder = DecoderPart(tgt_vocab_size, d_model, num_heads, dff, num_layers)\n","    self.final_layer = nn.Linear(d_model, tgt_vocab_size)\n","\n","  def forward(self, src, tgt, mask):\n","    encoder_output = self.encoder(src)\n","    decoder_output = self.decoder(tgt, encoder_output, mask)\n","    output = self.final_layer(decoder_output)\n","\n","    return output"]},{"cell_type":"code","execution_count":94,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1750945557737,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"WPuHunfGzMsN"},"outputs":[],"source":["toy_data = [\n","    (\"i love you\", \"je t'aime\"),\n","    (\"how are you\", \"comment ça va\"),\n","    (\"good morning\", \"bonjour\"),\n","    (\"thank you\", \"merci\"),\n","    (\"good night\", \"bonne nuit\"),\n","    (\"see you soon\", \"à bientôt\"),\n","]\n","\n"]},{"cell_type":"code","execution_count":95,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1750945557778,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"ytRmWIc5IgU3"},"outputs":[],"source":["class Vocab:\n","    def __init__(self, sentences):\n","        self.special = ['<pad>', '<sos>', '<eos>', '<unk>']\n","        words = set(w for s in sentences for w in s.split())\n","        self.itos = self.special + sorted(words)\n","        self.stoi = {w: i for i, w in enumerate(self.itos)}\n","\n","    def encode(self, sentence, max_len=10):\n","        tokens = ['<sos>'] + sentence.split() + ['<eos>']\n","        tokens += ['<pad>'] * (max_len - len(tokens))\n","        return [self.stoi.get(t, self.stoi['<unk>']) for t in tokens]\n","\n","    def decode(self, indices):\n","        return ' '.join([self.itos[i] for i in indices if self.itos[i] not in ['<sos>', '<eos>', '<pad>']])\n","\n","src_vocab = Vocab([s for s, _ in toy_data])\n","tgt_vocab = Vocab([t for _, t in toy_data])"]},{"cell_type":"code","execution_count":96,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1750945557780,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"_CFLoC9SOKm-"},"outputs":[],"source":["def get_tensor_pairs(data, src_vocab, tgt_vocab, max_len=10):\n","    src, tgt = [], []\n","    for s, t in data:\n","        src.append(torch.tensor(src_vocab.encode(s, max_len)))\n","        tgt.append(torch.tensor(tgt_vocab.encode(t, max_len)))\n","    return torch.stack(src), torch.stack(tgt)\n","\n","src_tensor, tgt_tensor = get_tensor_pairs(toy_data, src_vocab, tgt_vocab)"]},{"cell_type":"code","execution_count":97,"metadata":{"executionInfo":{"elapsed":2960,"status":"ok","timestamp":1750945560734,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"uqmjGETuOSDx"},"outputs":[],"source":["model = Transformer(\n","    src_vocab_size=len(src_vocab.itos),\n","    tgt_vocab_size=len(tgt_vocab.itos),\n","    d_model=128,\n","    num_heads=4,\n","    num_layers=2,\n","    dff=256\n",")"]},{"cell_type":"code","execution_count":98,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1750945560742,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"},"user_tz":-330},"id":"YCcENpwqOX4m"},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss(ignore_index=src_vocab.stoi['<pad>'])\n","\n","def create_mask(seq_len):\n","    return torch.tril(torch.ones(seq_len, seq_len)).unsqueeze(0)"]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YKD7bA-xR_Wb","executionInfo":{"status":"ok","timestamp":1750945719363,"user_tz":-330,"elapsed":158617,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}},"outputId":"a960a3e6-8ad8-44e0-d223-771fadd016e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 2.6658\n","Epoch 2, Loss: 2.8954\n","Epoch 3, Loss: 2.2919\n","Epoch 4, Loss: 2.2657\n","Epoch 5, Loss: 2.1421\n","Epoch 6, Loss: 2.0681\n","Epoch 7, Loss: 1.9790\n","Epoch 8, Loss: 1.8050\n","Epoch 9, Loss: 1.6190\n","Epoch 10, Loss: 1.5253\n"]}],"source":["for epoch in range(10):\n","    model.train()\n","    optimizer.zero_grad()\n","\n","    tgt_input = tgt_tensor[:, :-1]\n","    tgt_out = tgt_tensor[:, 1:]\n","    mask = create_mask(tgt_input.shape[1])\n","\n","    logits = model(src_tensor, tgt_input, mask)\n","    loss = criterion(logits.reshape(-1, logits.size(-1)), tgt_out.reshape(-1))\n","    loss.backward()\n","    optimizer.step()\n","\n","    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"]},{"cell_type":"code","execution_count":103,"metadata":{"id":"AiGyBu4dSJFu","executionInfo":{"status":"ok","timestamp":1750945832547,"user_tz":-330,"elapsed":5,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}}},"outputs":[],"source":["def translate(sentence, max_len=10):\n","    model.eval()\n","    # Assuming device is defined elsewhere, e.g., device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    src = torch.tensor(src_vocab.encode(sentence, max_len)).unsqueeze(0).to(device)\n","    tgt = torch.tensor([[tgt_vocab.stoi['<sos>']]], dtype=torch.long).to(device)\n","\n","    for _ in range(max_len):\n","        mask = create_mask(tgt.shape[1]).to(device)\n","        out = model(src, tgt, mask)\n","        # next_token shape after argmax is (batch_size,) which is (1,) in this case\n","        # unsqueeze(0) makes it (1, 1) which matches the last dimension of tgt for concatenation along dim=1\n","        next_token = out[:, -1].argmax(-1).unsqueeze(0)\n","        tgt = torch.cat([tgt, next_token], dim=1) # Concatenate (1, seq_len) and (1, 1) along dim 1\n","        if next_token.item() == tgt_vocab.stoi['<eos>']:\n","            break\n","\n","    return tgt_vocab.decode(tgt.squeeze().tolist())"]},{"cell_type":"code","source":["print(\"English: good night\")\n","print(\"French : \", translate(\"good night\", 10))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H3xEbmxlf3NX","executionInfo":{"status":"ok","timestamp":1750945839334,"user_tz":-330,"elapsed":4569,"user":{"displayName":"MOHAMMED GHAYAZ Z AI&DS","userId":"16438552079538621449"}},"outputId":"1add0132-bb5b-4bc4-daca-ac4c080c59c6"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stdout","text":["English: good night\n","French :  bonne bonne bonne bonne bonne bonne bonne bonne bonne bonne\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"tnqTiNVXf7CG"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyM5lD7MQVZSsmaF+uNl66bO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}